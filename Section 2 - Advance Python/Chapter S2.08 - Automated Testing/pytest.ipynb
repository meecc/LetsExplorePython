{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pytest` framework are one of the most advanced & flexible testing frameworks available in `Python`. They can be used for your smallest to largest testing needs. \n",
    "\n",
    "It also supports third party plugins and there are litterally hundreds to them. The consolidated list of plugins can be found at https://pytest.readthedocs.io/en/2.7.3/plugins_index/index.html. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** An example of a simple test:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from app import increment\n",
    "\n",
    "def test_will_fail():\n",
    "    \"\"\"\n",
    "        \"increment(3)\" should return 4, but since we are\n",
    "        evaluating it against 5, the test should fail.\n",
    "    \"\"\"\n",
    "    assert increment(3) == 5\n",
    "\n",
    "\n",
    "def test_will_pass():\n",
    "    \"\"\".\"\"\"\n",
    "    assert increment(4) == 5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pytest` is not part of default installation of python and needs to be manually installed, which can be done by executing following command "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip install -U pytest --user\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your first test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the above example of `pytest` based test file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri May 12 04:16:14 2017.\n",
    "\n",
    "@author: johri_m.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def increment(x):\n",
    "    \"\"\".\"\"\"\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "def test_will_fail():\n",
    "    \"\"\".\"\"\"\n",
    "    assert increment(3) == 5\n",
    "\n",
    "\n",
    "def test_will_pass():\n",
    "    \"\"\".\"\"\"\n",
    "    assert increment(4) == 5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, `increment` is the function under test. and `test_will_fail` and `test_will_pass` are the test methods.\n",
    "\n",
    "> **<center>Note</center>**\n",
    "<hr>\n",
    "> Both the test methods name start with `test`. So all test functions should have name start with `test`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing Testcases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  `pytest` without options "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pytest` when executed without options will search for all the tests in current folder and all subfolders and execute them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ pytest \n",
    "============================= test session starts ==============================\n",
    "platform linux -- Python 3.6.1, pytest-3.5.0, py-1.5.3, pluggy-0.6.0\n",
    "rootdir: /home/mayank/code/mj/ebooks/python/lep/Section 2 - Advance Python/Chapter S2.08 - Automated Testing/code/pytest/basics, inifile:\n",
    "plugins: bdd-2.20.0, allure-pytest-2.3.2b1\n",
    "collected 14 items                                                             \n",
    "\n",
    "python_test.py .                                                         [  7%]\n",
    "test_basic_1.py F.                                                       [ 21%]\n",
    "test_basics_1_1.py .F...                                                 [ 57%]\n",
    "test_class_1.py .F.                                                      [ 78%]\n",
    "test_class_2.py ..                                                       [ 92%]\n",
    "test_fixture_1.py .                                                      [100%]\n",
    "\n",
    "=================================== FAILURES ===================================\n",
    "________________________________ test_will_fail ________________________________\n",
    "\n",
    "    def test_will_fail():\n",
    "        \"\"\".\"\"\"\n",
    ">       assert increment(3) == 5\n",
    "E       assert 4 == 5\n",
    "E        +  where 4 = increment(3)\n",
    "\n",
    "test_basic_1.py:16: AssertionError\n",
    "______________________ TestClass.test_validate_attr_wrong ______________________\n",
    "\n",
    "self = <test_basics_1_1.TestClass object at 0x7f9c0a58db00>\n",
    "\n",
    "    def test_validate_attr_wrong(self):\n",
    "        x = User\n",
    ">       assert hasattr(x, 'fullname')\n",
    "E       AssertionError: assert False\n",
    "E        +  where False = hasattr(<class 'test_basics_1_1.User'>, 'fullname')\n",
    "\n",
    "test_basics_1_1.py:26: AssertionError\n",
    "______________________ TestClass.test_validate_attr_wrong ______________________\n",
    "\n",
    "self = <test_class_1.TestClass object at 0x7f9c0a30b358>\n",
    "\n",
    "    def test_validate_attr_wrong(self):\n",
    "        x = User\n",
    ">       assert hasattr(x, 'fullname')\n",
    "E       AssertionError: assert False\n",
    "E        +  where False = hasattr(<class 'test_class_1.User'>, 'fullname')\n",
    "\n",
    "test_class_1.py:26: AssertionError\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ pytest basic_1.py \n",
    "============================= test session starts ==============================\n",
    "platform linux -- Python 3.6.1, pytest-3.5.0, py-1.5.3, pluggy-0.6.0\n",
    "rootdir: /home/mayank/code/mj/ebooks/python/lep/Section 2 - Advance Python/Chapter S2.08 - Automated Testing/code/pytest/basics, inifile:\n",
    "plugins: bdd-2.20.0\n",
    "collected 2 items                                                              \n",
    "\n",
    "basic_1.py F.                                                            [100%]\n",
    "\n",
    "=================================== FAILURES ===================================\n",
    "________________________________ test_will_fail ________________________________\n",
    "\n",
    "    def test_will_fail():\n",
    "        \"\"\".\"\"\"\n",
    ">       assert increment(3) == 5\n",
    "E       assert 4 == 5\n",
    "E        +  where 4 = increment(3)\n",
    "\n",
    "basic_1.py:16: AssertionError\n",
    "====================== 1 failed, 1 passed in 0.03 seconds ======================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see that, pytest scanned the folder for all the files which contains the text `test`, and then it searched for all the functions with text `test` in their names. \n",
    "\n",
    "After it has found all the tests to execute, it starts the execute and proide the execution details. Once all the tests are executed, it provides a summary of all the testcases which failed and also provides the assert details of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "test_basic_1.py F.                                                       [ 21%]\n",
    "test_basics_1_1.py .F...                                                 [ 57%]\n",
    "test_class_1.py .F.                                                      [ 78%]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the summary, you will find that `pytest` has marked (by \"**`F`**\") all the files in which tests have failed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `pytest  with options` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pytest` provides lots of `command-line` options, here we are going to cover few of the most comman onces later in the chapter. \n",
    "\n",
    "`pytest -h` provides a summary of all the `command-line` options available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ pytest -q basic_1.py \n",
    "F.                                                                       [100%]\n",
    "=================================== FAILURES ===================================\n",
    "________________________________ test_will_fail ________________________________\n",
    "\n",
    "    def test_will_fail():\n",
    "        \"\"\".\"\"\"\n",
    ">       assert increment(3) == 5\n",
    "E       assert 4 == 5\n",
    "E        +  where 4 = increment(3)\n",
    "\n",
    "basic_1.py:16: AssertionError\n",
    "1 failed, 1 passed in 0.02 seconds\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running through `python`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ python -m pytest basic_1.py \n",
    "============================= test session starts ==============================\n",
    "platform linux -- Python 3.6.1, pytest-3.5.0, py-1.5.3, pluggy-0.6.0\n",
    "rootdir: /home/mayank/code/mj/ebooks/python/lep/Section 2 - Advance Python/Chapter S2.08 - Automated Testing/code/pytest/basics, inifile:\n",
    "plugins: bdd-2.20.0\n",
    "collected 2 items                                                              \n",
    "\n",
    "basic_1.py F.                                                            [100%]\n",
    "\n",
    "=================================== FAILURES ===================================\n",
    "________________________________ test_will_fail ________________________________\n",
    "\n",
    "    def test_will_fail():\n",
    "        \"\"\".\"\"\"\n",
    ">       assert increment(3) == 5\n",
    "E       assert 4 == 5\n",
    "E        +  where 4 = increment(3)\n",
    "\n",
    "basic_1.py:16: AssertionError\n",
    "====================== 1 failed, 1 passed in 0.02 seconds ======================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Allows for compact test suites\n",
    "> The idioms that `pytest` first introduced brought a change in the Python community because they made it possible for test suites to be written in a very compact style, or at least far more compact than was ever possible before.\n",
    "> Pytest basically introduced the concept that Python tests should be plain Python functions instead of forcing developers to include their tests inside large test classes.\n",
    "\n",
    "- Minimal boilerplate\n",
    "> Tests written with `pytest` need very little boilerplate code, which makes them easy to write and understand.\n",
    "\n",
    "- Tests parametrization\n",
    "> You can parametrize any test and cover all uses of a unit without code duplication.\n",
    "\n",
    "- Very pretty and useful failure information\n",
    "> `Pytest` rewrites your test so that it can store all intermediate values that can lead to failing `assert` and provides you with very pretty explanation about what has been asserted and what have failed.\n",
    "\n",
    "- `fixture`'s are simple and easy to use\n",
    "> A `fixture` is just a function that returns a value and to use a fixture you just have to add an argument to your test function. You can also use a fixture from another fixture in the same manner, so it's easy to make them modular.\n",
    "You can also parametrize fixture and every test that uses it will run with all values of parameters, no test rewrite needed. If your test uses several fixtures, all parameters' combinations will be covered.\n",
    "\n",
    "- Pdb just works\n",
    "> Pytest `**automagically**` (and safely) disables output capturing when you're entering pdb, so you don't have to redirect debugger to other console or bear huge amount of unneeded output from other tests.\n",
    "\n",
    "- Test discovery by file-path\n",
    "\n",
    "- Over 150 plugins \n",
    "> more than 150 plugins to customise py.test such as pytest-BDD and pytest-konira for writing tests for Behaviour Driven Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compatibility Issues\n",
    "> The fact that pytest uses it's own special routines to write tests means that you are trading convenience for compatibility. In other words, writing tests for pytest means that you are tying yourself to only pytest and the only way to use another testing framework is to rewrite most of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salient Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pytest Fixtures\n",
    "- Introspect agent\n",
    "- Test parametrization\n",
    "- Pytest Markers (Custom and inbuilt)\n",
    "- Plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Py.test command line options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pytest -h\n",
    "usage: pytest [options] [file_or_dir] [file_or_dir] [...]\n",
    "\n",
    "positional arguments:\n",
    "  file_or_dir\n",
    "\n",
    "general:\n",
    "  -k EXPRESSION         only run tests which match the given substring\n",
    "                        expression. An expression is a python evaluatable\n",
    "                        expression where all names are substring-matched\n",
    "                        against test names and their parent classes. Example:\n",
    "                        -k 'test_method or test_other' matches all test\n",
    "                        functions and classes whose name contains\n",
    "                        'test_method' or 'test_other', while -k 'not\n",
    "                        test_method' matches those that don't contain\n",
    "                        'test_method' in their names. Additionally keywords\n",
    "                        are matched to classes and functions containing extra\n",
    "                        names in their 'extra_keyword_matches' set, as well as\n",
    "                        functions which have names assigned directly to them.\n",
    "  -m MARKEXPR           only run tests matching given mark expression.\n",
    "                        example: -m 'mark1 and not mark2'.\n",
    "  --markers             show markers (builtin, plugin and per-project ones).\n",
    "  -x, --exitfirst       exit instantly on first error or failed test.\n",
    "  --maxfail=num         exit after first num failures or errors.\n",
    "  --strict              marks not registered in configuration file raise\n",
    "                        errors.\n",
    "  -c file               load configuration from `file` instead of trying to\n",
    "                        locate one of the implicit configuration files.\n",
    "  --continue-on-collection-errors\n",
    "                        Force test execution even if collection errors occur.\n",
    "  --rootdir=ROOTDIR     Define root directory for tests. Can be relative path:\n",
    "                        'root_dir', './root_dir', 'root_dir/another_dir/';\n",
    "                        absolute path: '/home/user/root_dir'; path with\n",
    "                        variables: '$HOME/root_dir'.\n",
    "  --fixtures, --funcargs\n",
    "                        show available fixtures, sorted by plugin appearance\n",
    "  --fixtures-per-test   show fixtures per test\n",
    "  --import-mode={prepend,append}\n",
    "                        prepend/append to sys.path when importing test\n",
    "                        modules, default is to prepend.\n",
    "  --pdb                 start the interactive Python debugger on errors.\n",
    "  --pdbcls=modulename:classname\n",
    "                        start a custom interactive Python debugger on errors.\n",
    "                        For example:\n",
    "                        --pdbcls=IPython.terminal.debugger:TerminalPdb\n",
    "  --capture=method      per-test capturing method: one of fd|sys|no.\n",
    "  -s                    shortcut for --capture=no.\n",
    "  --runxfail            run tests even if they are marked xfail\n",
    "  --lf, --last-failed   rerun only the tests that failed at the last run (or\n",
    "                        all if none failed)\n",
    "  --ff, --failed-first  run all tests but run the last failures first. This\n",
    "                        may re-order tests and thus lead to repeated fixture\n",
    "                        setup/teardown\n",
    "  --nf, --new-first     run tests from new files first, then the rest of the\n",
    "                        tests sorted by file mtime\n",
    "  --cache-show          show cache contents, don't perform collection or tests\n",
    "  --cache-clear         remove all cache contents at start of test run.\n",
    "  --lfnf={all,none}, --last-failed-no-failures={all,none}\n",
    "                        change the behavior when no test failed in the last\n",
    "                        run or no information about the last failures was\n",
    "                        found in the cache\n",
    "\n",
    "reporting:\n",
    "  -v, --verbose         increase verbosity.\n",
    "  -q, --quiet           decrease verbosity.\n",
    "  --verbosity=VERBOSE   set verbosity\n",
    "  -r chars              show extra test summary info as specified by chars\n",
    "                        (f)ailed, (E)error, (s)skipped, (x)failed, (X)passed,\n",
    "                        (p)passed, (P)passed with output, (a)all except pP.\n",
    "                        Warnings are displayed at all times except when\n",
    "                        --disable-warnings is set\n",
    "  --disable-warnings, --disable-pytest-warnings\n",
    "                        disable warnings summary\n",
    "  -l, --showlocals      show locals in tracebacks (disabled by default).\n",
    "  --tb=style            traceback print mode (auto/long/short/line/native/no).\n",
    "  --show-capture={no,stdout,stderr,log,all}\n",
    "                        Controls how captured stdout/stderr/log is shown on\n",
    "                        failed tests. Default is 'all'.\n",
    "  --full-trace          don't cut any tracebacks (default is to cut).\n",
    "  --color=color         color terminal output (yes/no/auto).\n",
    "  --durations=N         show N slowest setup/test durations (N=0 for all).\n",
    "  --pastebin=mode       send failed|all info to bpaste.net pastebin service.\n",
    "  --junit-xml=path      create junit-xml style report file at given path.\n",
    "  --junit-prefix=str    prepend prefix to classnames in junit-xml output\n",
    "  --result-log=path     DEPRECATED path for machine-readable result log.\n",
    "  --gherkin-terminal-reporter\n",
    "                        enable gherkin output\n",
    "\n",
    "collection:\n",
    "  --collect-only        only collect tests, don't execute them.\n",
    "  --pyargs              try to interpret all arguments as python packages.\n",
    "  --ignore=path         ignore path during collection (multi-allowed).\n",
    "  --deselect=nodeid_prefix\n",
    "                        deselect item during collection (multi-allowed).\n",
    "  --confcutdir=dir      only load conftest.py's relative to specified dir.\n",
    "  --noconftest          Don't load any conftest.py files.\n",
    "  --keep-duplicates     Keep duplicate tests.\n",
    "  --collect-in-virtualenv\n",
    "                        Don't ignore tests in a local virtualenv directory\n",
    "  --doctest-modules     run doctests in all .py modules\n",
    "  --doctest-report={none,cdiff,ndiff,udiff,only_first_failure}\n",
    "                        choose another output format for diffs on doctest\n",
    "                        failure\n",
    "  --doctest-glob=pat    doctests file matching pattern, default: test*.txt\n",
    "  --doctest-ignore-import-errors\n",
    "                        ignore doctest ImportErrors\n",
    "  --doctest-continue-on-failure\n",
    "                        for a given doctest, continue to run after the first\n",
    "                        failure\n",
    "\n",
    "test session debugging and configuration:\n",
    "  --basetemp=dir        base temporary directory for this test run.\n",
    "  --version             display pytest lib version and import information.\n",
    "  -h, --help            show help message and configuration info\n",
    "  -p name               early-load given plugin (multi-allowed). To avoid\n",
    "                        loading of plugins, use the `no:` prefix, e.g.\n",
    "                        `no:doctest`.\n",
    "  --trace-config        trace considerations of conftest.py files.\n",
    "  --debug               store internal tracing debug information in\n",
    "                        'pytestdebug.log'.\n",
    "  -o OVERRIDE_INI, --override-ini=OVERRIDE_INI\n",
    "                        override ini option with \"option=value\" style, e.g.\n",
    "                        `-o xfail_strict=True -o cache_dir=cache`.\n",
    "  --assert=MODE         Control assertion debugging tools. 'plain' performs no\n",
    "                        assertion debugging. 'rewrite' (the default) rewrites\n",
    "                        assert statements in test modules on import to provide\n",
    "                        assert expression information.\n",
    "  --setup-only          only setup fixtures, do not execute tests.\n",
    "  --setup-show          show setup of fixtures while executing tests.\n",
    "  --setup-plan          show what fixtures and tests would be executed but\n",
    "                        don't execute anything.\n",
    "\n",
    "pytest-warnings:\n",
    "  -W PYTHONWARNINGS, --pythonwarnings=PYTHONWARNINGS\n",
    "                        set which warnings to report, see -W option of python\n",
    "                        itself.\n",
    "\n",
    "logging:\n",
    "  --no-print-logs       disable printing caught logs on failed tests.\n",
    "  --log-level=LOG_LEVEL\n",
    "                        logging level used by the logging module\n",
    "  --log-format=LOG_FORMAT\n",
    "                        log format as used by the logging module.\n",
    "  --log-date-format=LOG_DATE_FORMAT\n",
    "                        log date format as used by the logging module.\n",
    "  --log-cli-level=LOG_CLI_LEVEL\n",
    "                        cli logging level.\n",
    "  --log-cli-format=LOG_CLI_FORMAT\n",
    "                        log format as used by the logging module.\n",
    "  --log-cli-date-format=LOG_CLI_DATE_FORMAT\n",
    "                        log date format as used by the logging module.\n",
    "  --log-file=LOG_FILE   path to a file when logging will be written to.\n",
    "  --log-file-level=LOG_FILE_LEVEL\n",
    "                        log file logging level.\n",
    "  --log-file-format=LOG_FILE_FORMAT\n",
    "                        log format as used by the logging module.\n",
    "  --log-file-date-format=LOG_FILE_DATE_FORMAT\n",
    "                        log date format as used by the logging module.\n",
    "\n",
    "Cucumber JSON:\n",
    "  --cucumber-json=path  create cucumber json style report file at given path.\n",
    "  --cucumber-json-expanded\n",
    "                        expand scenario outlines into scenarios and fill in\n",
    "                        the step names\n",
    "  --generate-missing    Generate missing bdd test code for given feature files\n",
    "                        and exit.\n",
    "  --feature=FILE_OR_DIR\n",
    "                        Feature file or directory to generate missing code\n",
    "                        for. Multiple allowed.\n",
    "\n",
    "\n",
    "[pytest] ini-options in the first pytest.ini|tox.ini|setup.cfg file found:\n",
    "\n",
    "  markers (linelist)       markers for test functions\n",
    "  empty_parameter_set_mark (string) default marker for empty parametersets\n",
    "  norecursedirs (args)     directory patterns to avoid for recursion\n",
    "  testpaths (args)         directories to search for tests when no files or dire\n",
    "  console_output_style (string) console output: classic or with additional progr\n",
    "  usefixtures (args)       list of default fixtures to be used with this project\n",
    "  python_files (args)      glob-style file patterns for Python test module disco\n",
    "  python_classes (args)    prefixes or glob names for Python test class discover\n",
    "  python_functions (args)  prefixes or glob names for Python test function and m\n",
    "  xfail_strict (bool)      default for the strict parameter of xfail markers whe\n",
    "  junit_suite_name (string) Test suite name for JUnit report\n",
    "  junit_logging (string)   Write captured log messages to JUnit report: one of n\n",
    "  doctest_optionflags (args) option flags for doctests\n",
    "  doctest_encoding (string) encoding used for doctest files\n",
    "  cache_dir (string)       cache directory path.\n",
    "  filterwarnings (linelist) Each line specifies a pattern for warnings.filterwar\n",
    "  log_print (bool)         default value for --no-print-logs\n",
    "  log_level (string)       default value for --log-level\n",
    "  log_format (string)      default value for --log-format\n",
    "  log_date_format (string) default value for --log-date-format\n",
    "  log_cli (bool)           enable log display during test run (also known as \"li\n",
    "  log_cli_level (string)   default value for --log-cli-level\n",
    "  log_cli_format (string)  default value for --log-cli-format\n",
    "  log_cli_date_format (string) default value for --log-cli-date-format\n",
    "  log_file (string)        default value for --log-file\n",
    "  log_file_level (string)  default value for --log-file-level\n",
    "  log_file_format (string) default value for --log-file-format\n",
    "  log_file_date_format (string) default value for --log-file-date-format\n",
    "  addopts (args)           extra command line options\n",
    "  minversion (string)      minimally required pytest version\n",
    "\n",
    "environment variables:\n",
    "  PYTEST_ADDOPTS           extra command line options\n",
    "  PYTEST_PLUGINS           comma-separated plugins to load during startup\n",
    "  PYTEST_DEBUG             set to enable debug tracing of pytest's internals\n",
    "\n",
    "\n",
    "to see available markers type: pytest --markers\n",
    "to see available fixtures type: pytest --fixtures\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Pytest` important command line options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `-v` (increase verbosity.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ pytest -v basic_1.py \n",
    "========================================================================= test session starts ==========================================================================\n",
    "platform linux -- Python 3.6.1, pytest-3.5.0, py-1.5.3, pluggy-0.6.0 -- /usr/bin/python3.6\n",
    "cachedir: .pytest_cache\n",
    "rootdir: /home/mayank/code/mj/ebooks/python/lep/Section 2 - Advance Python/Chapter S2.08 - Automated Testing/code/pytest/basics, inifile:\n",
    "plugins: bdd-2.20.0\n",
    "collected 2 items                                                                                                                                                      \n",
    "\n",
    "basic_1.py::test_will_fail FAILED                                                                                                                                [ 50%]\n",
    "basic_1.py::test_will_pass PASSED                                                                                                                                [100%]\n",
    "\n",
    "=============================================================================== FAILURES ===============================================================================\n",
    "____________________________________________________________________________ test_will_fail ____________________________________________________________________________\n",
    "\n",
    "    def test_will_fail():\n",
    "        \"\"\".\"\"\"\n",
    ">       assert increment(3) == 5\n",
    "E       assert 4 == 5\n",
    "E        +  where 4 = increment(3)\n",
    "\n",
    "basic_1.py:16: AssertionError\n",
    "================================================================== 1 failed, 1 passed in 0.02 seconds ==================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `-q` (decrease verbosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ pytest -q basic_1.py \n",
    "F.                                                                                                                                                               [100%]\n",
    "=============================================================================== FAILURES ===============================================================================\n",
    "____________________________________________________________________________ test_will_fail ____________________________________________________________________________\n",
    "\n",
    "    def test_will_fail():\n",
    "        \"\"\".\"\"\"\n",
    ">       assert increment(3) == 5\n",
    "E       assert 4 == 5\n",
    "E        +  where 4 = increment(3)\n",
    "\n",
    "basic_1.py:16: AssertionError\n",
    "1 failed, 1 passed in 0.02 seconds\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `-s` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is shortcut for `--capture=no`. What that means is, all the `print` outputs will be displayed on the `stdout` console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "pytest -s test_basic_1.py \n",
    "============================= test session starts ==============================\n",
    "platform linux -- Python 3.6.1, pytest-3.5.0, py-1.5.3, pluggy-0.6.0\n",
    "rootdir: /home/mayank/code/mj/ebooks/python/lep/Section 2 - Advance Python/Chapter S2.08 - Automated Testing/code/pytest/basics, inifile:\n",
    "plugins: bdd-2.20.0, allure-pytest-2.3.2b1\n",
    "collected 2 items                                                              \n",
    "\n",
    "test_basic_1.py testing 3+1\n",
    "F.\n",
    "\n",
    "=================================== FAILURES ===================================\n",
    "________________________________ test_will_fail ________________________________\n",
    "\n",
    "    def test_will_fail():\n",
    "        \"\"\".\"\"\"\n",
    "        print(\"testing 3+1\")\n",
    ">       assert increment(3) == 5\n",
    "E       assert 4 == 5\n",
    "E        +  where 4 = increment(3)\n",
    "\n",
    "test_basic_1.py:17: AssertionError\n",
    "====================== 1 failed, 1 passed in 0.04 seconds ======================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example `testing 3+1` is getting printed on the console, which is output of a print command `print(\"testing 3+1\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  `--collect-only` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It collects all the testcases which can be executed and provides all the testcases it can execute. This is a good step to find how many testcases fulfill certain condition  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pytest  --collect-only  \n",
    "========================================================================= test session starts ==========================================================================\n",
    "platform linux -- Python 3.6.1, pytest-3.5.0, py-1.5.3, pluggy-0.6.0\n",
    "rootdir: /home/mayank/code/mj/ebooks/python/lep/Section 2 - Advance Python/Chapter S2.08 - Automated Testing/code/pytest, inifile:\n",
    "plugins: bdd-2.20.0\n",
    "collected 88 items                                                                                                                                                     \n",
    "<Module 'basics/python_test.py'>\n",
    "  <Class 'Test_PythonHomePage'>\n",
    "    <Instance '()'>\n",
    "      <Function 'test_search'>\n",
    "<Module 'fixtures/test_1.py'>\n",
    "  <Function 'test_fixture_contents'>\n",
    "  <Function 'test_try_to_break_the_fixture_1'>\n",
    "  <Function 'test_try_to_break_the_fixture_2'>\n",
    "  <Function 'test_try_to_break_the_module_fixture_1'>\n",
    "  <Function 'test_try_to_break_the_module_fixture_2'>\n",
    "\n",
    "- - - - - \n",
    "\n",
    "<Module 'fixtures/test_scope_1.py'>\n",
    "  <UnitTestCase 'MyTest'>\n",
    "    <TestCaseFunction 'test_method1'>\n",
    "    <TestCaseFunction 'test_method2'>\n",
    "<Module 'fixtures/test_scope_function.py'>\n",
    "  <UnitTestCase 'MyTest'>\n",
    "    <TestCaseFunction 'test_method1'>\n",
    "    <TestCaseFunction 'test_method2'>\n",
    "<Module 'my magic/test_5.py'>\n",
    "  <Function 'test_foo[FOO-1-1]'>\n",
    "  <Function 'test_foo[FOO-2--3]'>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running only on a directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pytest  --collect-only  my\\ magic/\n",
    "========================================================================= test session starts ==========================================================================\n",
    "platform linux -- Python 3.6.1, pytest-3.5.0, py-1.5.3, pluggy-0.6.0\n",
    "rootdir: /home/mayank/code/mj/ebooks/python/lep/Section 2 - Advance Python/Chapter S2.08 - Automated Testing/code/pytest, inifile:\n",
    "plugins: bdd-2.20.0\n",
    "collected 2 items                                                                                                                                                      \n",
    "<Module 'my magic/test_5.py'>\n",
    "  <Function 'test_foo[FOO-1-1]'>\n",
    "  <Function 'test_foo[FOO-2--3]'>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Launching PDB (Python Debugger) on failures or specific number of failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytest allows to launch `pdb` on first or `for` initial specific number of failures by using following command option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pytest --pdb  # launch pdb on every failure\n",
    "pytest -x --pdb   # launch pdb on first failure, then end test session\n",
    "pytest --pdb --maxfail=4  # launch pdb for first 4 failures\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --durations=n (Profiling test executions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pytest --durations=5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below command line will return the list of 5 slowest test executions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (`-m`) Run tests by marker expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytest allows to select marked testcases to execute as shown in the below example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pytest -m staging\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command will execute all the `testcases` marked with decorator `@pytest.mark.staging`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `--junitxml=path` (Creating `JUnitXML` format files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "$ pytest  --junitxml=\"report.xml\"\n",
    "===================== test session starts ========================\n",
    "platform linux -- Python 3.6.1, pytest-3.5.0, py-1.5.3, pluggy-0.6.0\n",
    "rootdir: /home/mayank/code/mj/ebooks/python/lep/Section 2 - Advance Python/Chapter S2.08 - Automated Testing/code/pytest, inifile:\n",
    "plugins: bdd-2.20.0, allure-pytest-2.3.2b1\n",
    "collected 88 items                                                                                                                                                     \n",
    "\n",
    "basics/python_test.py E                                                                                                                                          [  1%]\n",
    "fixtures/test_1.py ....F                                                                                                                                         [  6%]\n",
    "fixtures/test_2.py .                                                                                                                                             [  7%]\n",
    "fixtures/test_basic_1.py .                                                                                                                                       [  9%]\n",
    "fixtures/test_basics_0.py .                                                                                                                                      [ 10%]\n",
    "fixtures/test_basics_1.py ..                                                                                                                                     [ 12%]\n",
    "fixtures/test_basics_1_1.py ..                                                                                                                                   [ 14%]\n",
    "fixtures/test_basics_2.py ..                                                                                                                                     [ 17%]\n",
    "fixtures/test_mark_1.py ...                                                                                                                                      [ 20%]\n",
    "fixtures/test_mark_2.py ...                                                                                                                                      [ 23%]\n",
    "fixtures/test_pyfixture_1.py ..F                                                                                                                                 [ 27%]\n",
    "fixtures/test_pyfixture_2.py ..                                                                                                                                  [ 29%]\n",
    "fixtures/test_pyfixture_3.py ('args', ['var0', 'var1'], 'x', 1)\n",
    ".('args', ['var0', 'var1'], 'x', 2)\n",
    ".                                                                                                                                  [ 31%]\n",
    "fixtures/test_pyfixture_parameter_1.py ..................                                                                                                        [ 52%]\n",
    "fixtures/test_pyfixture_parameter_1_1.py ..................                                                                                                      [ 72%]\n",
    "fixtures/test_pyfixture_parameter_2.py ..................                                                                                                        [ 93%]\n",
    "fixtures/test_scope_1.py FF                                                                                                                                      [ 95%]\n",
    "fixtures/test_scope_function.py Fs                                                                                                                               [ 97%]\n",
    "my magic/test_5.py FF                                                                                                                                            [100%]\n",
    "\n",
    "============================ ERRORS ===================\n",
    "__________ ERROR at setup of Test_PythonHomePage.test_search __________\n",
    "\n",
    "cls = <class 'python_test.Test_PythonHomePage'>\n",
    "\n",
    "    @classmethod\n",
    "    def setup_class(cls):\n",
    "        \"\"\" setup any state specific to the execution of the given class (which\n",
    "            usually contains tests).\n",
    "            \"\"\"\n",
    ">       with open(\"config.yaml\", 'r') as stream:\n",
    "E       FileNotFoundError: [Errno 2] No such file or directory: 'config.yaml'\n",
    "\n",
    "basics/python_test.py:10: FileNotFoundError\n",
    "\n",
    "============================= FAILURES ===============\n",
    "__________________________ test_try_to_break_the_module_fixture_2 ________________________\n",
    "\n",
    "i_also_set_things_up = {'status': 'doing fine'}\n",
    "\n",
    "    def test_try_to_break_the_module_fixture_2(i_also_set_things_up):\n",
    ">       assert i_also_set_things_up['flashing'] == \"dicts can't flash!\"\n",
    "E       KeyError: 'flashing'\n",
    "\n",
    "fixtures/test_1.py:28: KeyError\n",
    "\n",
    "-------------------- Captured stdout setup ----------\n",
    "Dummy DB Creation\n",
    "_______________________ MyTest.test_method2 _________\n",
    "\n",
    "self = <test_scope_1.MyTest testMethod=test_method2>\n",
    "\n",
    "    def test_method2(self):\n",
    ">       assert 0, self.db   # fail for demo purposes\n",
    "E       AssertionError: <test_scope_1.db_class.<locals>.DummyDB object at 0x7f05795ab9b0>\n",
    "E       assert 0\n",
    "\n",
    "fixtures/test_scope_1.py:37: AssertionError\n",
    "\n",
    "------------ generated xml file: /home/mayank/code/mj/ebooks/python/lep/Section 2 - Advance Python/Chapter S2.08 - Automated Testing/code/pytest/report.xml ------------\n",
    "\n",
    "================ 7 failed, 79 passed, 1 skipped, 1 error in 0.36 seconds ========\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixture is one of the most important concept in `pytest`. They have taken the concept of `setup` and `teardown` to next level by adding many customization such as \n",
    "\n",
    "- Function level selection\n",
    "- Module based selection\n",
    "\n",
    "Also, they can be used to provide baseline on which tests can be repeatedly executed reliably. \n",
    "\n",
    "- `fixture`'s have explicit names and are activated by declaring them in `test functions`, `modules`, `classes` or `whole projects`\n",
    "- `fixture`'s are `modular`, and `each fixture triggers` a `fixture` function which can use other `fixtures`\n",
    "- You can choose to parametrize `fixture`'s and tests according to configuration and component options, or to re-use `fixture`'s across `class`, `module` or `whole test session` scopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any method can be marked as fixture by adding `@pytest.fixture` gecorator to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "@pytest.fixture()\n",
    "def my_fixture():\n",
    "    print (\"This is a fixture\")\n",
    "    \n",
    "def test_my_fixture(my_fixture):\n",
    "    print (\"I'm the test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pyfixture_1.py\n",
    "import pytest\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture()\n",
    "def my_fixture():\n",
    "    print (\"This is a fixture\")\n",
    "    \n",
    "def test_my_fixture(my_fixture):\n",
    "    print (\"I'm the test\")\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def tester(request):\n",
    "    \"\"\"Create tester object\"\"\"\n",
    "    print(request.param)\n",
    "    return MyTester(request.param)\n",
    "\n",
    "\n",
    "class TestIt:\n",
    "    @pytest.mark.parametrize('tester', [['var1', 'var2']], indirect=True)\n",
    "    def test_tc1(self, tester):\n",
    "       tester.dothis()\n",
    "       assert 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying tests / selecting tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pytest test_mod.py   # run tests in module\n",
    "pytest somepath      # run all tests below somepath\n",
    "pytest -k stringexpr # only run tests with names that match the\n",
    "                      # \"string expression\", e.g. \"MyClass and not method\"\n",
    "                      # will select TestMyClass.test_something\n",
    "                      # but not TestMyClass.test_method_simple\n",
    "pytest test_mod.py::test_func  # only run tests that match the \"node ID\",\n",
    "                                # e.g. \"test_mod.py::test_func\" will select\n",
    "                                # only test_func in test_mod.py\n",
    "pytest test_mod.py::TestClass::test_method  # run a single method in\n",
    "                                             # a single class\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running multiple tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytest will run all files in the current directory and its subdirectories of the form test_*.py or *_test.py. More generally, it follows standard test discovery rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> pytest somepath  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asserting that a certain exception is raised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# content of test_sysexit.py\n",
    "import pytest\n",
    "def f():\n",
    "    raise SystemExit(1)\n",
    "\n",
    "def test_mytest():\n",
    "    with pytest.raises(SystemExit):\n",
    "        f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping multiple tests in a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestClass:\n",
    "    def test_one(self):\n",
    "        x = \"this\"\n",
    "        assert 'h' in x\n",
    "\n",
    "    def test_two(self):\n",
    "        x = \"hello\"\n",
    "        assert hasattr(x, 'check')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Integration Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventions for Python test discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytest implements the following standard test discovery:\n",
    "\n",
    "- If no arguments are specified then collection starts from testpaths (if configured) or the current directory. Alternatively, command line arguments can be used in any combination of directories, file names or node ids.\n",
    "- Recurse into directories, unless they match norecursedirs.\n",
    "- In those directories, search for test_*.py or *_test.py files, imported by their test package name.\n",
    "- From those files, collect test items:\n",
    "    - test_ prefixed test functions or methods outside of class\n",
    "    - test_ prefixed test functions or methods inside Test prefixed test classes (without an __init__ method)\n",
    "    \n",
    "For examples of how to customize your test discovery Changing standard (Python) test discovery.\n",
    "\n",
    "Within Python modules, pytest also discovers tests using the standard unittest.TestCase subclassing technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a test layout / import rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytest supports two common test layouts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Tests outside application code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting tests into an extra directory outside your actual application code might be useful if you have many functional tests or for other reasons want to keep tests separate from actual application code (often a good idea):\n",
    "\n",
    "```\n",
    "setup.py\n",
    "mypkg/\n",
    "    __init__.py\n",
    "    app.py\n",
    "    view.py\n",
    "tests/\n",
    "    test_app.py\n",
    "    test_view.py\n",
    "    ...```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to have test modules with the same name, you might add __init__.py files to your tests folder and subfolders, changing them to packages:\n",
    "```\n",
    "setup.py\n",
    "mypkg/\n",
    "    ...\n",
    "tests/\n",
    "    __init__.py\n",
    "    foo/\n",
    "        __init__.py\n",
    "        test_view.py\n",
    "    bar/\n",
    "        __init__.py\n",
    "        test_view.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this situation, it is strongly suggested to use a src layout where application root package resides in a sub-directory of your root:\n",
    "```\n",
    "setup.py\n",
    "src/\n",
    "    mypkg/\n",
    "        __init__.py\n",
    "        app.py\n",
    "        view.py\n",
    "tests/\n",
    "    __init__.py\n",
    "    foo/\n",
    "        __init__.py\n",
    "        test_view.py\n",
    "    bar/\n",
    "        __init__.py\n",
    "        test_view.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests as part of application code\n",
    "\n",
    "Inlining test directories into your application package is useful if you have direct relation between tests and application modules and want to distribute them along with your application:\n",
    "```\n",
    "setup.py\n",
    "mypkg/\n",
    "    __init__.py\n",
    "    app.py\n",
    "    view.py\n",
    "    test/\n",
    "        __init__.py\n",
    "        test_app.py\n",
    "        test_view.py\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scheme, it is easy to your run tests using the --pyargs option:\n",
    "\n",
    "```pytest --pyargs mypkg```\n",
    "\n",
    "pytest will discover where mypkg is installed and collect tests from there.\n",
    "\n",
    "Note that this layout also works in conjunction with the src layout mentioned in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Calling pytest from Python code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can invoke pytest from Python code directly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`pytest.main()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this acts as if you would call “pytest” from the command line. It will not raise SystemExit but return the exitcode instead. You can pass in options and arguments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`pytest.main(['-x', 'mytestdir'])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://docs.pytest.org/en/latest/usage.html#specifying-tests-selecting-tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

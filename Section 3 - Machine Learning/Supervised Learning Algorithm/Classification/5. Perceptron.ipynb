{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Perceptron is another simple algorithm suitable for large scale learning. By default:\n",
    "\n",
    "- It does not require a learning rate.\n",
    "- It is not regularized (penalized).\n",
    "- It updates its model only on mistakes.\n",
    "\n",
    "The last characteristic implies that the Perceptron is slightly faster to train than SGD with the hinge loss and that the resulting models are sparser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron can be used for supervised learning and can be used to solve binary linear classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n",
      "0.753333333333\n",
      "[ 6.8 -8.9  8.8 -3.5] [ 6.8 -8.9  8.8 -3.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from sklearn.utils.testing import assert_array_almost_equal\n",
    "from sklearn.utils.testing import assert_greater\n",
    "from sklearn.utils.testing import assert_raises\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "random_state = check_random_state(12)\n",
    "indices = np.arange(iris.data.shape[0])\n",
    "random_state.shuffle(indices)\n",
    "X = iris.data[indices]\n",
    "y = iris.target[indices]\n",
    "X_csr = sp.csr_matrix(X)\n",
    "X_csr.sort_indices()\n",
    "\n",
    "\n",
    "class MyPerceptron(object):\n",
    "\n",
    "    def __init__(self, n_iter=1):\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.w = np.zeros(n_features, dtype=np.float64)\n",
    "        self.b = 0.0\n",
    "\n",
    "        for t in range(self.n_iter):\n",
    "            for i in range(n_samples):\n",
    "                if self.predict(X[i])[0] != y[i]:\n",
    "                    self.w += y[i] * X[i]\n",
    "                    self.b += y[i]\n",
    "\n",
    "    def project(self, X):\n",
    "        return np.dot(X, self.w) + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.atleast_2d(X)\n",
    "        return np.sign(self.project(X))\n",
    "\n",
    "\n",
    "def test_perceptron_accuracy():\n",
    "    for data in (X, X_csr):\n",
    "        clf = Perceptron(max_iter=100, tol=None, shuffle=False)\n",
    "        clf.fit(data, y)\n",
    "        score = clf.score(data, y)\n",
    "        print(score)\n",
    "        assert_greater(score, 0.7)\n",
    "\n",
    "\n",
    "def test_perceptron_correctness():\n",
    "    y_bin = y.copy()\n",
    "    y_bin[y != 1] = -1\n",
    "\n",
    "    clf1 = MyPerceptron(n_iter=2)\n",
    "    clf1.fit(X, y_bin)\n",
    "\n",
    "    clf2 = Perceptron(max_iter=2, shuffle=False, tol=None)\n",
    "    clf2.fit(X, y_bin)\n",
    "\n",
    "    assert_array_almost_equal(clf1.w, clf2.coef_.ravel())\n",
    "    print(clf1.w, clf2.coef_.ravel())\n",
    "\n",
    "\n",
    "def test_undefined_methods():\n",
    "    clf = Perceptron(max_iter=100)\n",
    "    for meth in (\"predict_proba\", \"predict_log_proba\"):\n",
    "        assert_raises(AttributeError, lambda x: getattr(clf, x), meth)\n",
    "        \n",
    "        \n",
    "test_perceptron_accuracy()\n",
    "test_perceptron_correctness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference \n",
    "- https://maviccprp.github.io/a-perceptron-in-just-a-few-lines-of-python-code/\n",
    "- https://datasciencelab.wordpress.com/2014/01/10/machine-learning-classics-the-perceptron\n",
    "- http://scikit-learn.org/stable/modules/linear_model.html#perceptron\n",
    "- https://en.wikipedia.org/wiki/Perceptron\n",
    "- \"Online Passive-Aggressive Algorithms\" K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR 7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

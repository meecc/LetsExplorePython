
# Gaussian Naive Bayes Classification

For most classification problems, it’s nice to have a simple, fast method to provide a quick baseline classification. If the simple and fast method is sufficient, then we don’t have to waste CPU cycles on more complex models. If not, we can use the results of the simple method to give us clues about our data.

One good method to keep in mind is Gaussian Naive Bayes (`sklearn.naive_bayes.GaussianNB`).

Gaussian Naive Bayes fits a Gaussian distribution to each training label independantly on each feature, and uses this to quickly give a rough classification. It is generally not sufficiently accurate for real-world data, but can perform surprisingly well, for instance on text data.


```python
from sklearn.datasets import load_digits
digits = load_digits()
```


```python
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
```


```python
X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target)
```


```python
print(len(X_train), len(X_test), y_train, y_test)
```

    1347 450 [8 9 9 ..., 5 6 8] [2 5 4 0 6 3 5 4 9 4 7 2 7 9 2 7 0 4 7 5 0 7 7 3 8 6 5 3 2 4 7 4 2 1 1 5 9
     0 0 3 8 0 0 2 6 5 5 9 4 7 4 7 3 8 8 0 9 2 8 1 9 0 3 2 7 8 0 4 3 9 6 0 0 8
     1 8 3 5 0 7 4 9 1 8 0 7 8 8 6 0 8 7 2 2 0 6 8 6 6 3 7 7 7 9 5 7 9 2 0 4 6
     0 6 1 7 2 2 3 5 7 2 7 6 1 8 3 0 8 2 5 1 4 8 1 0 4 2 5 0 5 3 6 0 3 3 7 6 4
     0 6 3 7 6 9 1 2 4 4 0 4 8 5 0 7 6 3 1 7 8 8 9 7 9 9 8 9 5 4 3 3 2 8 0 9 4
     0 2 4 9 1 6 6 4 1 9 7 1 6 4 2 0 6 2 4 7 8 6 8 1 9 2 1 3 2 5 2 7 1 0 6 4 0
     9 9 4 4 7 9 7 3 0 9 7 5 1 9 0 0 8 8 3 3 1 9 5 1 5 8 6 0 3 7 0 2 5 8 2 0 7
     2 5 2 2 5 6 9 3 9 7 7 9 4 2 7 9 6 4 8 5 6 0 0 2 4 6 9 2 4 7 4 9 4 2 6 3 0
     9 5 5 1 2 3 1 9 4 5 5 3 8 8 8 3 6 5 9 3 3 5 2 9 0 3 9 4 1 5 5 7 8 1 0 1 2
     4 0 7 7 5 4 8 3 8 1 1 9 8 0 7 9 0 8 6 4 4 3 6 9 0 9 4 2 9 9 0 1 4 7 4 6 0
     5 5 8 5 5 9 5 3 7 7 7 0 3 2 8 4 3 9 5 4 1 2 5 4 6 8 4 1 2 0 4 3 6 8 3 0 0
     9 7 1 5 7 1 3 1 6 5 2 7 8 8 1 8 7 7 7 9 8 4 7 4 3 0 8 3 3 8 8 4 1 5 0 6 1
     1 0 4 7 6 0]



```python
clf = GaussianNB()
clf.fit(X_train, y_train)
```




    GaussianNB(priors=None)




```python
predicted = clf.predict(X_test)
expected = y_test
print(predicted)
print(expected)
```

    [2 5 4 0 6 3 5 4 9 4 7 2 7 8 2 7 0 4 7 5 0 7 7 3 8 6 5 3 2 4 7 4 2 8 8 5 9
     0 0 3 8 0 0 2 6 5 5 9 7 7 4 7 3 8 8 0 9 2 8 8 7 0 3 2 7 8 0 4 3 9 6 0 0 8
     1 8 8 5 0 7 4 9 1 8 0 7 8 8 6 0 8 7 2 2 0 6 8 6 6 8 7 7 7 9 5 7 9 2 0 7 6
     0 6 9 7 8 2 3 5 7 2 7 6 1 5 8 0 8 2 5 8 4 8 1 0 4 2 5 0 7 3 6 0 3 8 7 6 4
     0 6 3 7 6 9 8 2 4 4 0 6 8 5 0 7 6 3 8 7 8 1 9 7 9 9 8 9 5 4 7 3 2 8 0 9 4
     0 2 4 8 1 6 6 4 1 9 7 1 6 4 1 0 6 2 7 7 8 6 8 1 8 8 1 8 2 6 4 7 1 0 6 4 0
     3 8 4 4 7 3 7 8 0 9 7 5 1 7 0 0 8 8 3 8 1 9 8 8 5 8 6 0 3 7 0 2 5 8 2 0 7
     8 5 8 8 5 6 7 7 9 7 7 9 4 8 7 1 6 4 8 5 6 0 0 2 4 6 5 1 4 7 7 9 4 2 6 3 0
     9 4 5 2 2 3 8 8 4 5 5 3 8 1 8 3 6 5 9 7 3 5 8 9 0 3 9 4 1 5 5 7 8 1 0 1 2
     4 0 7 7 5 4 8 3 8 8 1 8 8 0 7 9 0 8 6 4 4 3 6 9 0 9 4 2 0 9 0 1 4 7 4 6 0
     5 5 8 5 5 9 5 3 7 7 7 0 1 2 8 4 3 9 5 4 6 2 5 4 6 8 4 8 2 0 4 2 6 8 3 0 0
     9 7 7 5 7 1 8 1 6 5 2 7 8 8 9 8 7 7 7 9 8 4 7 4 3 0 8 3 8 8 8 4 1 5 0 6 1
     1 0 4 7 6 0]
    [2 5 4 0 6 3 5 4 9 4 7 2 7 9 2 7 0 4 7 5 0 7 7 3 8 6 5 3 2 4 7 4 2 1 1 5 9
     0 0 3 8 0 0 2 6 5 5 9 4 7 4 7 3 8 8 0 9 2 8 1 9 0 3 2 7 8 0 4 3 9 6 0 0 8
     1 8 3 5 0 7 4 9 1 8 0 7 8 8 6 0 8 7 2 2 0 6 8 6 6 3 7 7 7 9 5 7 9 2 0 4 6
     0 6 1 7 2 2 3 5 7 2 7 6 1 8 3 0 8 2 5 1 4 8 1 0 4 2 5 0 5 3 6 0 3 3 7 6 4
     0 6 3 7 6 9 1 2 4 4 0 4 8 5 0 7 6 3 1 7 8 8 9 7 9 9 8 9 5 4 3 3 2 8 0 9 4
     0 2 4 9 1 6 6 4 1 9 7 1 6 4 2 0 6 2 4 7 8 6 8 1 9 2 1 3 2 5 2 7 1 0 6 4 0
     9 9 4 4 7 9 7 3 0 9 7 5 1 9 0 0 8 8 3 3 1 9 5 1 5 8 6 0 3 7 0 2 5 8 2 0 7
     2 5 2 2 5 6 9 3 9 7 7 9 4 2 7 9 6 4 8 5 6 0 0 2 4 6 9 2 4 7 4 9 4 2 6 3 0
     9 5 5 1 2 3 1 9 4 5 5 3 8 8 8 3 6 5 9 3 3 5 2 9 0 3 9 4 1 5 5 7 8 1 0 1 2
     4 0 7 7 5 4 8 3 8 1 1 9 8 0 7 9 0 8 6 4 4 3 6 9 0 9 4 2 9 9 0 1 4 7 4 6 0
     5 5 8 5 5 9 5 3 7 7 7 0 3 2 8 4 3 9 5 4 1 2 5 4 6 8 4 1 2 0 4 3 6 8 3 0 0
     9 7 1 5 7 1 3 1 6 5 2 7 8 8 1 8 7 7 7 9 8 4 7 4 3 0 8 3 3 8 8 4 1 5 0 6 1
     1 0 4 7 6 0]


### Quantitative Measurement of Performance


```python
matches = (predicted == expected)
print(matches)
```

    [ True  True  True  True  True  True  True  True  True  True  True  True
      True False  True  True  True  True  True  True  True  True  True  True
      True  True  True  True  True  True  True  True  True False False  True
      True  True  True  True  True  True  True  True  True  True  True  True
     False  True  True  True  True  True  True  True  True  True  True False
     False  True  True  True  True  True  True  True  True  True  True  True
      True  True  True  True False  True  True  True  True  True  True  True
      True  True  True  True  True  True  True  True  True  True  True  True
      True  True  True False  True  True  True  True  True  True  True  True
      True False  True  True  True False  True False  True  True  True  True
      True  True  True  True False False  True  True  True  True False  True
      True  True  True  True  True  True  True False  True  True  True  True
     False  True  True  True  True  True  True  True  True  True False  True
      True  True  True False  True  True  True  True  True  True False  True
      True False  True  True  True  True  True  True  True  True False  True
      True  True  True  True  True  True  True  True False  True  True  True
      True  True  True  True  True  True  True False  True  True  True False
      True  True  True  True  True False False  True False  True False False
      True  True  True  True  True  True False False  True  True  True False
      True False  True  True  True  True  True False  True  True  True  True
      True False  True  True False False  True  True  True  True  True  True
      True  True  True  True  True  True  True False  True False False  True
      True False False  True  True  True  True  True False  True False  True
      True  True  True  True  True  True  True  True  True False False  True
      True False  True  True  True  True  True  True  True False  True False
      True  True False False  True  True  True  True  True False  True  True
      True  True  True False  True  True False  True  True  True  True  True
      True  True  True  True  True  True  True  True  True  True  True  True
      True  True  True  True  True  True False  True False  True  True  True
      True  True  True  True  True  True  True  True  True  True  True  True
      True False  True  True  True  True  True  True  True  True  True  True
      True  True  True  True  True  True  True  True  True  True False  True
      True  True  True  True  True  True False  True  True  True  True  True
      True False  True  True  True False  True  True  True  True  True  True
      True False  True  True  True False  True  True  True  True  True  True
      True False  True  True  True  True  True  True  True  True  True  True
      True  True  True False  True  True  True  True  True  True  True  True
      True  True  True  True  True  True]



```python
print(matches.sum())
print(len(matches))
qmp = matches.sum() / float(len(matches))
print(qmp)
```

    364
    450
    0.808888888889


We see that more than 80% of the 450 predictions match the input. But there are other more sophisticated metrics that can be used to judge the performance of a classifier: several are available in the sklearn.metrics submodule.

One of the most useful metrics is the classification_report, which combines several measures and prints a table with the results:


```python
from sklearn import metrics
print(metrics.classification_report(expected, predicted))
```

                 precision    recall  f1-score   support
    
              0       0.95      1.00      0.98        41
              1       0.80      0.73      0.77        45
              2       0.93      0.58      0.71        43
              3       0.85      0.76      0.80        45
              4       0.94      0.75      0.84        44
              5       0.83      0.91      0.87        47
              6       0.81      0.96      0.88        48
              7       0.82      0.98      0.89        55
              8       0.52      0.85      0.65        40
              9       0.88      0.50      0.64        42
    
    avg / total       0.83      0.81      0.81       450
    


Another enlightening metric for this sort of multi-label classification is a confusion matrix: it helps us visualize which labels are being interchanged in the classification errors:


```python
print(metrics.confusion_matrix(expected, predicted))
```

    [[41  0  0  0  0  0  0  0  0  0]
     [ 0 33  0  0  0  0  4  0  7  1]
     [ 0  4 25  0  0  0  0  0 14  0]
     [ 0  0  1 34  0  4  0  2  2  2]
     [ 1  0  0  0 33  1  6  3  0  0]
     [ 0  0  0  2  0 43  1  0  1  0]
     [ 0  0  0  0  0  1 46  0  1  0]
     [ 0  0  0  0  1  0  0 54  0  0]
     [ 0  2  1  0  0  0  0  3 34  0]
     [ 1  2  0  4  1  3  0  4  6 21]]


the above metrix is shown as 0 1 2 3 4 5 6 7 8 9 both X and Y axis.

you can see that there is no confusion in 0 and there are 41 instances of it. 
you can see that there is some confusion in 1 and there are 31 instances it was correctly identified but it was confused with 6 ( 4 time), 8 (7 times) & 9 (1 time) and so on.  

We see here that the numbers 1, 2, 3, and 9 are often being labeled 8. 

